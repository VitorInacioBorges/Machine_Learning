# Machine Learning Basics

## Machine Learning Algorithm Structure
- Data Collection
- Pre-Processing
	- Cleaning
	- Normalization
	- Atribute Selection (caractheristics/filters):
		- The attributes are not always effective, for that is necessary to make a hyper parameterization.
- Division in Training and Testing
	- It results in metrics, that represent division between evaluation training and prevision testing.
- Model Training
- Evaluation (metrics)
- Practice Application

### Examples:
- Decision Tree
- Linear Regression
- etc.


## Naive Bayes
- Easy, fast and efficient
- Based in Bayes's theory
- It works with the probability of an event occuring
- Example: spam identification through key-words
- 3 Types and Cases:
	- GaussianNB()
	- MultinomialNB()
	- BernoulliNB()
- Metrics:
	- Accuracy
	- Precision
	- Recall
	- F1-score
	- Confusion Matrix


Collection of Data Sets and Bases:
- Kaggle
- GitHub / GitLab
- Excel / .CSVs
- Written Pannels
- Oral Searching
- Estatistic Methods in General

## Types
### Supervised
- Regression (not rotuled data but with steady values)
- Classification
	- Classic Algorithms
		- Clusterization 
			- K-means
		- KNN 
		- Naive Bayes
			- Bayesian Networks
		- Decision Tree
		- SVM (Support Vector Machine)
		- Perceptron
			- Neural Networks
		- Deep Learning
- Recurrent Neural Networks
### Not Supervised
- Grouping
- Dimensional Reduction
### By Reinforcement


## Supervised Model Experimental Protocol
- Cross Validation
	- Divides a DataSet in minor sets of data. Each one of them is trained with a different selection of values.
- Holdout
	- One part of data goes to training and the other goes to testing.
- Resubstitution


## Evaluation of Confusion Matrix
- TP (True Positive)
- TN (True Negative)
- FP (False Positive)
- FN (False Negative)


## Metrics

## MCS / SMC
- Multi-Classification System
	- Classification
	- Selection
	- Results Combination
